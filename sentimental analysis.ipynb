{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75ec9f0",
   "metadata": {},
   "source": [
    "  # SENTIMENTAL ANALYSIS WITH NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45137bed",
   "metadata": {},
   "source": [
    "Sentiment analysis, also known as opinion mining, is a valuable technique in natural language processing and machine learning. It involves determining the sentiment or emotional tone expressed in text data, which could be positive or negative. This project aims to perform sentiment analysis on a dataset of text reviews using a Multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b961bc0",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3837097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45d7c3",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3289a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#importing the datasets\n",
    "df_amazon = pd.read_csv(r\"C:\\Users\\VAGDEVI\\Desktop\\sentiment labelled sentences\\amazon_cells_labelled.txt\", delimiter = '\\t', quoting = 3, \n",
    "                header = None, names = ['Review', 'Score'])\n",
    "\n",
    "df_imdb = pd.read_csv(r\"C:\\Users\\VAGDEVI\\Desktop\\sentiment labelled sentences\\imdb_labelled.txt\", delimiter = '\\t', quoting = 3, \n",
    "                header = None, names = ['Review', 'Score'])\n",
    "\n",
    "df_yelp = pd.read_csv(r\"C:\\Users\\VAGDEVI\\Desktop\\sentiment labelled sentences\\yelp_labelled.txt\", delimiter = '\\t', \n",
    "                        quoting = 3, header = None, \n",
    "                        names = ['Review', 'Score'])\n",
    "print(df_amazon.shape)\n",
    "print(df_imdb.shape)\n",
    "print(df_yelp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a65bc",
   "metadata": {},
   "source": [
    "## Combining Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6113c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining dataframes into one\n",
    "\n",
    "df = pd.concat([df_yelp, df_imdb, df_amazon], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbc9d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a510771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Score\n",
       "0                              Wow... Loved this place.      1\n",
       "1                                    Crust is not good.      0\n",
       "2             Not tasty and the texture was just nasty.      0\n",
       "3     Stopped by during the late May bank holiday of...      1\n",
       "4     The selection on the menu was great and so wer...      1\n",
       "...                                                 ...    ...\n",
       "2995  The screen does get smudged easily because it ...      0\n",
       "2996  What a piece of junk.. I lose more calls on th...      0\n",
       "2997                       Item Does Not Match Picture.      0\n",
       "2998  The only thing that disappoint me is the infra...      0\n",
       "2999  You can not answer calls with the unit, never ...      0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465f1f6",
   "metadata": {},
   "source": [
    "## Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a95b6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Regular expressions\n",
    "#Text transformation\n",
    "df[\"lower\"]=df.Review.str.lower() #lowercase\n",
    "df[\"lower\"]=[str(data) for data in df.lower] #converting all to string\n",
    "df[\"lower\"]=df.lower.apply(lambda x: re.sub('[^A-Za-z0-9 ]+', ' ', x)) #regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3257f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow  loved this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the screen does get smudged easily because it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>what a piece of junk  i lose more calls on thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "      <td>item does not match picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "      <td>the only thing that disappoint me is the infra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you can not answer calls with the unit  never ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Score  \\\n",
       "0                              Wow... Loved this place.      1   \n",
       "1                                    Crust is not good.      0   \n",
       "2             Not tasty and the texture was just nasty.      0   \n",
       "3     Stopped by during the late May bank holiday of...      1   \n",
       "4     The selection on the menu was great and so wer...      1   \n",
       "...                                                 ...    ...   \n",
       "2995  The screen does get smudged easily because it ...      0   \n",
       "2996  What a piece of junk.. I lose more calls on th...      0   \n",
       "2997                       Item Does Not Match Picture.      0   \n",
       "2998  The only thing that disappoint me is the infra...      0   \n",
       "2999  You can not answer calls with the unit, never ...      0   \n",
       "\n",
       "                                                  lower  \n",
       "0                                wow  loved this place   \n",
       "1                                    crust is not good   \n",
       "2             not tasty and the texture was just nasty   \n",
       "3     stopped by during the late may bank holiday of...  \n",
       "4     the selection on the menu was great and so wer...  \n",
       "...                                                 ...  \n",
       "2995  the screen does get smudged easily because it ...  \n",
       "2996  what a piece of junk  i lose more calls on thi...  \n",
       "2997                       item does not match picture   \n",
       "2998  the only thing that disappoint me is the infra...  \n",
       "2999  you can not answer calls with the unit  never ...  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7d8c6",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenize the preprocessed text data into individual words using the `word_tokenize` function from the `nltk` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303353dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VAGDEVI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  5185\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "#Text splitting\n",
    "tokens_text = [word_tokenize(str(word)) for word in df.lower]\n",
    "#Unique word counter\n",
    "tokens_counter = [item for sublist in tokens_text for item in sublist]\n",
    "print(\"Number of tokens: \", len(set(tokens_counter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498764bf",
   "metadata": {},
   "source": [
    "## Stopword Removal\n",
    "Remove English stopwords from the tokenized text data using the stopwords from the `nltk` corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589bcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing english stopwords\n",
    "stopwords_nltk = nltk.corpus.stopwords\n",
    "stop_words = stopwords_nltk.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c86d3b",
   "metadata": {},
   "source": [
    "## Creating Predictor and Response Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0afd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create predictor and response vector\n",
    "\n",
    "X = df.iloc[:, 0]\n",
    "y = df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac1b73",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9521dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302740d2",
   "metadata": {},
   "source": [
    "## Creating Document Term Matrix (DTM) with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10fb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85032486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2400x4493 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25076 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn vocabulary of training data and create document term matrix\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38c24e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x4493 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5791 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform test set to create document term matrix from already learned\n",
    "# vocabulary\n",
    "\n",
    "X_test_dtm = vect.transform(X_test) \n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0c995",
   "metadata": {},
   "source": [
    "## Training a Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a84dbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc5f0503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6981403",
   "metadata": {},
   "source": [
    "## Making Predictions and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1de12c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class predictions for X_test_dtm\n",
    "\n",
    "y_pred_class = classifier.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f6de8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY = 82.667%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "print(f'ACCURACY = {accuracy * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d74f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[243,  47],\n",
       "       [ 57, 253]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68c66857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted probabilities for X_test_dtm\n",
    "\n",
    "y_pred_proba = classifier.predict_proba(X_test_dtm)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5e78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve = 90.467%\n"
     ]
    }
   ],
   "source": [
    "# Caluclate Area Under Curve\n",
    "\n",
    "area_under_curve = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'Area Under Curve = {area_under_curve * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad22298",
   "metadata": {},
   "source": [
    "## Sentiment Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71d63c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_input(input_text):\n",
    "    # Convert to lowercase\n",
    "    input_text = input_text.lower()\n",
    "    # Remove punctuation\n",
    "    input_text = re.sub('[^A-Za-z0-9 ]+', ' ', input_text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(input_text)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def predict_sentiment(user_input, classifier, vect):\n",
    "    preprocessed_input = preprocess_input(user_input)\n",
    "    user_input_dtm = vect.transform([preprocessed_input])\n",
    "    sentiment = classifier.predict(user_input_dtm)\n",
    "    return \"Positive\" if sentiment == 1 else \"Negative\"\n",
    "\n",
    "# Example usage:\n",
    "user_input = \" \"\n",
    "result = predict_sentiment(user_input, classifier, vect)\n",
    "print(f\"Predicted sentiment: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
